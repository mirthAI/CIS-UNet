{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bfa819e-23f4-407d-a852-74456b334bab",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div align=\"center\">\n",
    "    <h1>Prediction and Evaluation: CIS-UNet: Multi-Class Segmentation of the Aorta in Computed Tomography Angiography via Context-Aware Shifted Window Self-Attention</h1>    \n",
    "This notebook walks you through the steps required to predict segmentation files using the trained CIS-UNet model.\n",
    "    \n",
    "\n",
    "**It is assumed that your CIS_UNet model is trained, saved in the `saved_models` and ready to be used.**\n",
    "    \n",
    "\n",
    "</div>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Importing Libraries](#1-importing-libraries) \n",
    "2. [Helper Functions](#HelperFunctions)\n",
    "3. [Setting Up Parameters](#2-setting-up-parameters)\n",
    "4. [Loading Data](#3-loading-data)\n",
    "5. [Defining the Model](#4-defining-the-model)\n",
    "6. [Prediction and Evaluation (Cross-Validation)](#5-cross-validation-loop)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a585dc61-639e-4a9f-be7d-8d51be22f191",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries <a id='1-importing-libraries'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92a7af0-208b-41f9-9bb2-81889de95b61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.data import CacheDataset\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, ScaleIntensityRanged, CropForegroundd,\n",
    "    Orientationd, Spacingd, AsDiscrete\n",
    ")\n",
    "from monai.metrics import DiceMetric, SurfaceDistanceMetric\n",
    "import SimpleITK as sitk\n",
    "import seg_metrics.seg_metrics as sg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b718fdf-842a-497c-811c-7c87959ef39b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr>\n",
    "\n",
    "<a id='HelperFunctions'></a>\n",
    "## 2. Helper Function\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9fa087-22a4-4a56-a746-fdb594f40b34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_volumes(test_img, test_label, test_outputs, vol_name, results_dir):\n",
    "    \"\"\"\n",
    "    Save the test image, label, and predicted output as NIfTI files.\n",
    "\n",
    "    Args:\n",
    "        test_img : The test image tensor.\n",
    "        test_label : The ground truth label tensor.\n",
    "        test_outputs : The predicted output tensor.\n",
    "        vol_name (str): The volume name used for saving the files.\n",
    "        results_dir (str or Path): The directory where the results will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert results_dir to Path if it's not already\n",
    "    results_dir = Path(results_dir)\n",
    "\n",
    "    # Ensure results directory exists\n",
    "    results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Prepare image data for saving\n",
    "    img = test_img.detach().cpu().squeeze().permute(2, 1, 0)\n",
    "    img_sitk = sitk.GetImageFromArray(img.numpy())\n",
    "    img_sitk.SetDirection((-1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 1.0))\n",
    "    sitk.WriteImage(img_sitk, results_dir / f\"{vol_name}.nii.gz\")\n",
    "\n",
    "    # Prepare label data for saving\n",
    "    label = test_label.detach().cpu().squeeze().permute(2, 1, 0)\n",
    "    label_sitk = sitk.GetImageFromArray(label.numpy())\n",
    "    label_sitk.SetDirection((-1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 1.0))\n",
    "    sitk.WriteImage(label_sitk, results_dir / f\"{vol_name}_original.nii.gz\")\n",
    "\n",
    "    # Prepare predicted label data for saving\n",
    "    pred_label = torch.argmax(test_outputs, dim=1).detach().cpu().squeeze().permute(2, 1, 0)\n",
    "    pred_sitk = sitk.GetImageFromArray(pred_label.numpy())\n",
    "    pred_sitk.SetDirection((-1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 1.0))\n",
    "    sitk.WriteImage(pred_sitk, results_dir / f\"{vol_name}_predicted.nii.gz\")\n",
    "\n",
    "    # Confirmation message\n",
    "    print(f\"Results for {vol_name} saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8f958a-c315-494f-9c16-3e6070a5eebb",
   "metadata": {},
   "source": [
    "## 3. Setting Up Parameters <a id='1-importing-libraries'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6ad9b-7e06-4cef-8a87-bb9167618f1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the root and data directories\n",
    "data_dir = Path(\"../data\")\n",
    "root_dir = Path(\"./\")\n",
    "saved_model_dir = root_dir / \"saved_models\" / \"CIS_UNet\"\n",
    "results_dir = root_dir / \"results\" / \"CIS_UNet\"\n",
    "\n",
    "# Create directories if they do not exist\n",
    "saved_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Get CPU and GPU details\n",
    "num_gpus = torch.cuda.device_count()\n",
    "num_cpus = torch.get_num_threads()\n",
    "\n",
    "# Cross-validation parameters\n",
    "num_folds = 4\n",
    "\n",
    "# Model and data parameters\n",
    "spatial_dims = 3\n",
    "in_channels = 1\n",
    "num_classes = 15\n",
    "encoder_channels = [64, 128, 256, 512]\n",
    "feature_size = 48\n",
    "norm_name = 'instance'\n",
    "patch_size = 128\n",
    "num_samples = 4\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Define test transformations\n",
    "test_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"label\"], ensure_channel_first=True, image_only=False),\n",
    "    ScaleIntensityRanged(keys=[\"image\"], a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
    "    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\", allow_smaller=True),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 1.5), mode=(\"bilinear\", \"nearest\")),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0890858-382f-4a1f-84f3-3013c2f42ed9",
   "metadata": {},
   "source": [
    "## 4. Loading Data <a id='3-loading-data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac80d14-bcef-4d85-a170-7d2691529f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load image and label file paths\n",
    "images = sorted(glob.glob(os.path.join(data_dir, \"Volumes\", \"*.nii.gz\")))\n",
    "labels = sorted(glob.glob(os.path.join(data_dir, \"Labels\", \"*.nii.gz\")))\n",
    "files = [{\"image\": img, \"label\": lbl} for img, lbl in zip(images, labels)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51e7c8e-b8e2-4cb3-848e-4c212c099956",
   "metadata": {},
   "source": [
    "## 5. Defining the Model <a id='4-defining-the-model'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb5075e-ca0e-492b-8efb-f8784563d55c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model class definition\n",
    "from utils.CIS_UNet import CIS_UNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec938e2-146c-4535-994b-4f322e297f07",
   "metadata": {},
   "source": [
    "## 6. Prediction and Evaluation (Cross-Validation) <a id='5-cross-validation-loop'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970dbcb-d394-4fad-8cb9-595c70d53aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Initialize KFold\n",
    "skf = KFold(n_splits=num_folds, shuffle=True, random_state=92)\n",
    "\n",
    "# Iterate over each fold\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(files)):\n",
    "    print(f\"Fold {fold}/{num_folds-1}\")\n",
    "\n",
    "    # Create data loaders for validation sets\n",
    "    test_files = [files[i] for i in val_indices]\n",
    "    test_cache_num = len(test_files)\n",
    "    print(f\"Len: {len(val_indices)} | Test: index={val_indices}\")\n",
    "\n",
    "    # Initialize the model for testing\n",
    "    test_model = CIS_UNet(\n",
    "        spatial_dims=spatial_dims,\n",
    "        in_channels=in_channels,\n",
    "        num_classes=num_classes,\n",
    "        encoder_channels=encoder_channels\n",
    "    )\n",
    "\n",
    "    # Use DataParallel if multiple GPUs are available\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        test_model = torch.nn.DataParallel(test_model)\n",
    "\n",
    "    # Move the model to the appropriate device\n",
    "    test_model.to(device)\n",
    "\n",
    "    # Load the best model weights for the current fold\n",
    "    model_path = os.path.join(saved_model_dir, f'Fold{fold}_best_metric_model.pth')\n",
    "    print(f\"Loading Model: {model_path}\")\n",
    "    state_dict = torch.load(model_path)\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        new_state_dict[k[7:] if k.startswith('module.') else k] = v\n",
    "    test_model.load_state_dict(new_state_dict)\n",
    "\n",
    "    # Create the test dataset and data loader\n",
    "    test_ds = CacheDataset(data=test_files, transform=test_transforms, cache_num=test_cache_num, cache_rate=1.0, num_workers=num_cpus)\n",
    "    test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=num_cpus, pin_memory=True)\n",
    "\n",
    "    # Create the results directory for the current fold\n",
    "    result_dir = Path(results_dir) / f'Fold{fold}'\n",
    "    result_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_model.eval()\n",
    "    individual_dices = {}\n",
    "    individual_surface_scores = {}\n",
    "    mean_dice_coeff = []\n",
    "\n",
    "    # Disable gradient computation\n",
    "    with torch.no_grad():\n",
    "        for i, batch1 in enumerate(test_loader):\n",
    "            test_inputs, test_labels = batch1[\"image\"].to(device), batch1[\"label\"].to(device)\n",
    "            test_outputs = sliding_window_inference(test_inputs, (patch_size, patch_size, patch_size), num_samples, test_model)\n",
    "            \n",
    "            file_path = test_ds[i]['image_meta_dict']['filename_or_obj']\n",
    "            vol_name = os.path.basename(file_path).split('.')[0]\n",
    "            print(f'Processing Volume: {vol_name}')\n",
    "            \n",
    "            # Save the volumes\n",
    "            save_volumes(\n",
    "                test_img=test_inputs,\n",
    "                test_label=test_labels,\n",
    "                test_outputs=test_outputs,\n",
    "                vol_name=vol_name,\n",
    "                results_dir=result_dir\n",
    "            )\n",
    "\n",
    "    # Calculate metrics for each fold\n",
    "    gdth_fpaths = sorted(glob.glob(os.path.join(result_dir, '*original.nii.gz')))\n",
    "    pred_fpaths = sorted(glob.glob(os.path.join(result_dir, '*predicted.nii.gz')))\n",
    "    labels_fpaths = [{\"gdth_fpath\": gdth_label, \"pred_fpath\": pred_label} for gdth_label, pred_label in zip(gdth_fpaths, pred_fpaths)]\n",
    "\n",
    "    dice_results = {}\n",
    "    msd_results = {}\n",
    "    labels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "    segment_names = {\n",
    "        0: \"Aorta\", 1: \"Left Subclavian Artery\", 2: \"Celiac Artery\",\n",
    "        3: \"SMA\", 4: \"Left Renal Artery\", 5: \"Right Renal Artery\",\n",
    "        6: \"Left Common Iliac Artery\", 7: \"Right Common Iliac Artery\",\n",
    "        8: \"Innominate Artery\", 9: \"Left Common Carotid\", 10: \"Right External Iliac Artery\",\n",
    "        11: \"Right Internal Iliac Artery\", 12: \"Left External Iliac Artery\",\n",
    "        13: \"Left Internal Iliac Artery\"\n",
    "    }\n",
    "\n",
    "    # Compute metrics for each volume\n",
    "    for label_fp in labels_fpaths:\n",
    "        gdth_fpath = label_fp['gdth_fpath']\n",
    "        pred_fpath = label_fp['pred_fpath']\n",
    "        vol_name = os.path.basename(gdth_fpath).split(\"_\")[0]\n",
    "\n",
    "        # Read images and convert them to numpy arrays\n",
    "        gdth_img = sitk.ReadImage(gdth_fpath)\n",
    "        gdth_np = sitk.GetArrayFromImage(gdth_img)\n",
    "        pred_img = sitk.ReadImage(pred_fpath)\n",
    "        pred_np = sitk.GetArrayFromImage(pred_img)\n",
    "        spacing = np.array(list(reversed(pred_img.GetSpacing())))\n",
    "        \n",
    "        print(f\"Processing {vol_name} for metrics computation ...\")\n",
    "\n",
    "        # Calculate metrics\n",
    "        metrics = sg.write_metrics(\n",
    "            labels=labels,\n",
    "            gdth_img=gdth_np,\n",
    "            pred_img=pred_np,\n",
    "            csv_file=None,\n",
    "            spacing=spacing,\n",
    "            metrics=['msd', 'dice']\n",
    "        )\n",
    "        \n",
    "        dice_results[vol_name] = metrics[0]['dice']\n",
    "        msd_results[vol_name] = metrics[0]['msd']\n",
    "\n",
    "    # Save the metrics to CSV files\n",
    "    df_msd = pd.DataFrame(msd_results).T\n",
    "    df_msd[\"Labels' Avg\"] = df_msd.mean(axis=1)\n",
    "    df_msd.loc['Volume Avg'] = df_msd.mean(axis=0)\n",
    "    df_msd = df_msd.rename(index=segment_names)\n",
    "    df_msd.index.names = ['Segments']\n",
    "    df_msd.to_csv(result_dir / \"test_msd.csv\")\n",
    "\n",
    "    df_dice = pd.DataFrame(dice_results).T\n",
    "    df_dice[\"Labels' Avg\"] = df_dice.mean(axis=1)\n",
    "    df_dice.loc['Volume Avg'] = df_dice.mean(axis=0)\n",
    "    df_dice = df_dice.rename(index=segment_names)\n",
    "    df_dice.index.names = ['Segments']\n",
    "    df_dice.to_csv(result_dir / \"test_dice.csv\")\n",
    "\n",
    "    # Clean up to release memory\n",
    "    del test_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIQ_Kernel",
   "language": "python",
   "name": "miq_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
