{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4652f852-3c59-4923-8deb-744906369612",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h1>Training: CIS-UNet: Multi-Class Segmentation of the Aorta in Computed Tomography Angiography via Context-Aware Shifted Window Self-Attention</h1>    \n",
    "This notebook walks you through the steps required to train the CIS-UNet model.\n",
    "    \n",
    "\n",
    "</div>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Importing Libraries](#1-importing-libraries) \n",
    "2. [Helper Functions](#HelperFunctions)\n",
    "3. [Define Directories and Parameters](#4-Define-Directories-and-Parameters)\n",
    "4. [Data Preparation](#3-Data-Preparation)\n",
    "5. [Data Transformations](#Data-Transformations)\n",
    "6. [Model Training (K-fold Cross Validatoin)](#Model-Training-Cross-Validation)\n",
    "7. [Count Model Parameters](#Count-Model-Parameters)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d141a9-bb56-4144-98a4-1213ea4912c6",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries <a id='1-importing-libraries'></a>\n",
    "\n",
    "Importing all the required packages.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a140b770-5875-4838-9de6-e303d113962e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import glob\n",
    "import sys\n",
    "import monai\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    AsDiscrete, EnsureChannelFirstd, Compose, CropForegroundd,\n",
    "    LoadImaged, Orientationd, RandFlipd, RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd, ScaleIntensityRanged, RandRotate90d,\n",
    "    Spacingd, RandAffined\n",
    ")\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.data import DataLoader, CacheDataset, decollate_batch\n",
    "from monai.networks.layers import Norm\n",
    "from pathlib import Path\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import KFold\n",
    "from utils.CIS_UNet import CIS_UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a8e057-34e9-479b-8817-23b09df57d45",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Helper Functions <a id='HelperFunctions'></a>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f518f84-7d46-4666-ba61-c2399b43a216",
   "metadata": {},
   "source": [
    "### Print Setup Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33958e03-eb8c-4a19-9349-61966c238917",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to print setup details\n",
    "def print_setup_details():\n",
    "    print(\"#\" * 40, \"Setup Details\", \"#\" * 40)\n",
    "    versions = {\n",
    "        \"Package\": [\"OS, Shutil, and Glob\", \"Numpy\", \"Monai\", \"Torch\", \"SimpleITK\"],\n",
    "        \"Version\": [sys.version, np.__version__, monai.__version__, torch.__version__, sitk.__version__, sklearn.__version__]\n",
    "    }\n",
    "    versions_df = pd.DataFrame(versions)\n",
    "    print(tabulate(versions_df, headers=\"keys\", tablefmt=\"grid\"))\n",
    "\n",
    "    print(\"#\" * 40, \"Hardware Details\", \"#\" * 40)\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    num_cpus = torch.get_num_threads()\n",
    "    gpu_cpu_details = {\n",
    "        \"Component\": [\"GPUs\", \"CPUs\"],\n",
    "        \"Count\": [num_gpus, num_cpus]\n",
    "    }\n",
    "    gpu_cpu_df = pd.DataFrame(gpu_cpu_details)\n",
    "    print(tabulate(gpu_cpu_df, headers=\"keys\", tablefmt=\"grid\"))\n",
    "\n",
    "    if num_gpus > 0:\n",
    "        gpu_ids = {\"GPU ID\": [f\"GPU {gpu_id}\" for gpu_id in range(num_gpus)]}\n",
    "        gpu_ids_df = pd.DataFrame(gpu_ids)\n",
    "        print(tabulate(gpu_ids_df, headers=\"keys\", tablefmt=\"grid\"))\n",
    "\n",
    "    print(\"#\" * 40, \"Parameters Details\", \"#\" * 40)\n",
    "    setup_details = {\n",
    "        \"Parameter\": [\n",
    "            \"Number of Folds\", \"Number of Samples\", \"Patch Size\",\n",
    "            \"Spatial Dimensions\", \"Block Inplanes\", \"Layers\",\n",
    "            \"In Channels\", \"Number of Classes\", \"Encoder Channels\",\n",
    "            \"Feature Size\", \"Normalization Name\"\n",
    "        ],\n",
    "        \"Value\": [\n",
    "            num_folds, num_samples, patch_size, spatial_dims, block_inplanes, layers, in_channels, \n",
    "            num_classes, encoder_channels, feature_size, norm_name\n",
    "        ]\n",
    "    }\n",
    "    setup_df = pd.DataFrame(setup_details)\n",
    "    print(tabulate(setup_df, headers=\"keys\", tablefmt=\"grid\"))\n",
    "    print('#' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b87de22-d34b-4235-a6f8-8b1e066a1adf",
   "metadata": {},
   "source": [
    "### KFold Cross-Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442f1b32-1c62-4b45-b24f-37ae7434c77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform KFold cross-validation\n",
    "def perform_cross_validation(files, skf, train_test_files):\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(files)):\n",
    "        print(f\"Fold {i + 1}:\")\n",
    "        print(f\"  Training set:\")\n",
    "        print(f\"    Number of samples: {len(train_index)}\")\n",
    "        print(f\"    Indices: {train_index}\\n\")\n",
    "        print(f\"  Validation set:\")\n",
    "        print(f\"    Number of samples: {len(test_index)}\")\n",
    "        print(f\"    Indices: {test_index}\\n\")\n",
    "\n",
    "        train_files = [files[i] for i in train_index]\n",
    "        val_files = [files[i] for i in test_index]\n",
    "        train_test_files[f'Fold_{i + 1}_train_files'] = train_files\n",
    "        train_test_files[f'Fold_{i + 1}_test_files'] = val_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c3d7d0-7ede-4b00-b373-9a6f87456efc",
   "metadata": {},
   "source": [
    "### Model Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c671e5b8-2b89-46e0-98d8-64ba95d90175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for model validation\n",
    "def validation(epoch_iterator_val):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in epoch_iterator_val:\n",
    "            val_inputs, val_labels = batch[\"image\"].cuda(), batch[\"label\"].cuda()\n",
    "            val_outputs = sliding_window_inference(val_inputs, (patch_size, patch_size, patch_size), num_samples, model)\n",
    "            val_labels_list = decollate_batch(val_labels)\n",
    "            val_labels_convert = [post_label(val_label_tensor) for val_label_tensor in val_labels_list]\n",
    "            val_outputs_list = decollate_batch(val_outputs)\n",
    "            val_output_convert = [post_pred(val_pred_tensor) for val_pred_tensor in val_outputs_list]\n",
    "            dice_metric(y_pred=val_output_convert, y=val_labels_convert)\n",
    "            epoch_iterator_val.set_description(f\"Validate ({global_step} / {max_iterations} Steps)\")\n",
    "        mean_dice_val = dice_metric.aggregate().item()\n",
    "        dice_metric.reset()\n",
    "    return mean_dice_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b208bb-b746-4f97-879e-823e7ee24de6",
   "metadata": {},
   "source": [
    "### Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679a9a3a-2f7f-4ffc-9df4-8c1cb975ac90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function for model training\n",
    "def train(global_step, train_loader, val_loader, dice_val_best, global_step_best, fold):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    epoch_iterator = tqdm(train_loader, desc=f\"Training ({global_step} / {max_iterations} Steps) (loss=X.X)\", dynamic_ncols=True)\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        step += 1\n",
    "        x, y = batch[\"image\"].cuda(), batch[\"label\"].cuda()\n",
    "        logit_map = model(x)\n",
    "        loss = loss_function(logit_map, y)\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_iterator.set_description(f\"Training ({global_step} / {max_iterations} Steps) (loss={loss:.5f})\")\n",
    "        if (global_step % eval_num == 0 and global_step != 0) or global_step == max_iterations:\n",
    "            epoch_iterator_val = tqdm(val_loader, desc=f\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "            dice_val = validation(epoch_iterator_val)\n",
    "            epoch_loss /= step\n",
    "            epoch_loss_values.append(epoch_loss)\n",
    "            metric_values.append(dice_val)\n",
    "            if dice_val > dice_val_best:\n",
    "                dice_val_best = dice_val\n",
    "                global_step_best = global_step\n",
    "                torch.save(model.state_dict(), os.path.join(saved_model_dir, f'Fold{fold}_best_metric_model.pth'))\n",
    "                print(f\"Model Was Saved! Current Best Avg. Dice: {dice_val_best} | Current Avg. Dice: {dice_val}\")\n",
    "            else:\n",
    "                print(f\"Model Was Not Saved! Current Best Avg. Dice: {dice_val_best} | Current Avg. Dice: {dice_val}\")\n",
    "        global_step += 1\n",
    "    return global_step, dice_val_best, global_step_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb41c40b-15c1-4fef-9cbb-f16eb8cd0323",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 3. Define Directories and Parameters <a id='4-Define-Directories-and-Parameters'></a>\n",
    " \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a71b33-a1fe-43ba-8c74-3d54fd458dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define directories and parameters\n",
    "ver = \"CIS_UNet\"\n",
    "data_dir = Path(\"../data\")\n",
    "root_dir = Path(\"./\")\n",
    "saved_model_dir = root_dir / \"saved_models\" / ver\n",
    "results_dir = root_dir / \"results\" / ver\n",
    "saved_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "num_cpus = torch.get_num_threads()\n",
    "\n",
    "num_folds = 4\n",
    "num_samples = 4\n",
    "patch_size = 128\n",
    "spatial_dims = 3\n",
    "block_inplanes = (64, 128, 256, 512) \n",
    "layers = (3, 4, 6, 3)\n",
    "in_channels = 1\n",
    "num_classes = 15\n",
    "encoder_channels = [64, block_inplanes[0], block_inplanes[1], block_inplanes[2]]\n",
    "feature_size = 48\n",
    "norm_name = 'instance'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d581c20-8966-4ca5-a1b8-dfa68411992b",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 4. Data Preparation <a id='3-Data-Preparation'></a>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e60cce3-64a3-4b6d-b554-47585872ae77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = sorted(glob.glob(os.path.join(data_dir, \"Volumes\", \"*.nii.gz\")))\n",
    "labels = sorted(glob.glob(os.path.join(data_dir, \"Labels\", \"*.nii.gz\")))\n",
    "files = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(images, labels)]\n",
    "\n",
    "skf = KFold(n_splits=num_folds, shuffle=True, random_state=92)\n",
    "train_test_files = {}\n",
    "perform_cross_validation(files, skf, train_test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780bf624-77aa-41f9-a6e7-cfb8c0c1511d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr>\n",
    "\n",
    "## 5. Data Transformations <a id='Data-Transformations'></a>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d649dd-bfda-42c4-aac5-c62968d0ab02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"label\"], ensure_channel_first=True, image_only=False),\n",
    "    ScaleIntensityRanged(keys=[\"image\"], a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
    "    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\", allow_smaller=True),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 1.5), mode=(\"bilinear\", \"nearest\")),\n",
    "    RandCropByPosNegLabeld(keys=[\"image\", \"label\"], label_key=\"label\", spatial_size=(patch_size, patch_size, patch_size),\n",
    "                           pos=1, neg=1, num_samples=num_samples, image_key=\"image\", image_threshold=0),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], spatial_axis=[0, 1, 2], prob=0.10),\n",
    "    RandRotate90d(keys=[\"image\", \"label\"], prob=0.10, max_k=3),\n",
    "    RandShiftIntensityd(keys=[\"image\"], offsets=0.10, prob=0.50),\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"label\"], ensure_channel_first=True, image_only=False),\n",
    "    ScaleIntensityRanged(keys=[\"image\"], a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
    "    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\", allow_smaller=True),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 1.5), mode=(\"bilinear\", \"nearest\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa16898-a6ce-43d6-ba73-f1acd71da9ba",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 6. Model Training (K-fold Cross Validatoin) <a id='Model-Training-Cross-Validation'></a>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477182ec-af06-4878-8a2b-c7728303a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_label = AsDiscrete(to_onehot=num_classes)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=num_classes)\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "global_step = 0\n",
    "dice_val_best = 0.0\n",
    "global_step_best = 0\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "\n",
    "# Run the k-fold cross-validation and training\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(files)):\n",
    "    print(f\"Processing Fold {fold+1}\")\n",
    "    train_files = [files[i] for i in train_indices]\n",
    "    val_files = [files[i] for i in val_indices]\n",
    "\n",
    "    train_ds = CacheDataset(data=train_files, transform=train_transforms,\n",
    "                            cache_num=len(train_files), cache_rate=1.0, num_workers=8)\n",
    "    train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=num_cpus//2, pin_memory=True)\n",
    "    val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_num=len(val_files), cache_rate=1.0, num_workers=num_cpus//2)\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=num_cpus//2, pin_memory=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = CIS_UNet(spatial_dims=spatial_dims, in_channels=in_channels, num_classes=num_classes, encoder_channels=encoder_channels)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    loss_function = DiceCELoss(to_onehot_y=True, softmax=True, include_background=False)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "    max_iterations = 5\n",
    "    eval_num = 35\n",
    "    global_step = 0\n",
    "    dice_val_best = 0.0\n",
    "    global_step_best = 0\n",
    "    epoch_loss_values = []\n",
    "    metric_values = []\n",
    "\n",
    "    while global_step < max_iterations:\n",
    "        global_step, dice_val_best, global_step_best = train(global_step, train_loader, val_loader, dice_val_best, global_step_best, fold=fold)\n",
    "\n",
    "    print(f\"Global Step: {global_step} | Best Dice: {dice_val_best} | Global Best: {global_step_best}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ae2ba-1540-4af1-a6be-b3496b93081c",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Count Model Parameters <a id='Count-Model-Parameters'></a>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b10bba-b482-40b5-9a8f-b1d9c5923568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "\n",
    "# Compute the number of parameters\n",
    "num_params = count_parameters(model)\n",
    "print(\"Number of parameters: \", num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce439a7c-16ca-4efb-9eec-78a0fd0422c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIQ_Kernel",
   "language": "python",
   "name": "miq_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
